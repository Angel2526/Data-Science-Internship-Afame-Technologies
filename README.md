# Data Science | Internship 

# Iris Flower Classification ğŸŒ¸
## Overview
The Iris flower dataset is a classic dataset introduced by the British statistician and biologist Ronald Fisher in his 1936 paper, The Use of Multiple Measurements in Taxonomic Problems. The dataset is often referred to as Anderson's Iris data set due to Edgar Andersonâ€™s collection of the data. It consists of 150 samples from three species of Iris flowers: Iris-setosa, Iris-virginica, and Iris-versicolor. Four features were measured for each sample: sepal length, sepal width, petal length, and petal width, all in centimeters. This dataset is commonly used for classification tasks in machine learning, including support vector machines and other classification techniques.


## Objective ğŸ¯
The objective of this project is to develop a machine learning model that can classify Iris flowers into their respective species based on their sepal and petal measurements. Using this dataset, the goal is to create a model that accurately predicts the species of Iris flowers, making it a great introductory project for classification tasks.


## Dataset ğŸ“Š
The dataset used in this project is the well-known Iris dataset. It consists of the following columns:

sepal_length: Length of the sepal in cm

sepal_width: Width of the sepal in cm

petal_length: Length of the petal in cm

petal_width: Width of the petal in cm


species: The species of the Iris flower (Iris-setosa, Iris-versicolor, Iris-virginica)



## Steps


ğŸŸ€ Import Libraries ğŸ“š
 
ğŸŸ€ Read and Explore Dataset ğŸ”

ğŸŸ€ Data Wrangling ğŸ§¹

ğŸŸ€ Exploratory Data Analysis (EDA) ğŸ“ˆ

ğŸŸ€ Feature Engineering & Data Pre-processing ğŸ› ï¸

ğŸŸ€ Model Implementation & Evaluation ğŸ¤–


### Import Libraries

- import pandas as pd

- import numpy as np

- import matplotlib.pyplot as plt

- import seaborn as sns



### Exploratory Data Analysis (EDA) ğŸ”


The EDA involves visualizing the data to understand the distributions and relationships between features. This includes:

Histograms of feature distributions ğŸ“Š

Scatter plots of feature relationships ğŸŒ

Pair plots and correlation heatmaps ğŸ”¥



### Feature Engineering & Data Pre-processing ğŸ› ï¸


Encoding Categorical Data ğŸ” 

Data Scaling and Splitting ğŸ§ª

Model Implementation & Evaluation ğŸ¤–


### Different classification models were implemented and evaluated, including:


ğŸŸ€ Logistic Regression

ğŸŸ€ Decision Tree Classifier

ğŸŸ€ K-Nearest Neighbors Classifier

ğŸŸ€ Support Vector Machine

ğŸŸ€ Gaussian Naive Bayes

ğŸŸ€ Random Forest Classifier

ğŸŸ€ Each model was evaluated using metrics such as accuracy, precision, recall, and confusion matrices.


## Results ğŸ“ˆ


The models were compared based on their performance metrics. Key results include accuracy scores for each model, confusion matrices, and classification reports.
The project includes evaluations of various models, such as:


### Logistic Regression: 
Achieved an accuracy of 93% on the test set.

### Decision Tree Classifier: 
Achieved an accuracy of 89% on the test set.

### K-Nearest Neighbors (KNN): 
Achieved an accuracy of 93% on the test set.

### Support Vector Machine (SVM): 
Achieved an accuracy of 96% on the test set.

### Gaussian Naive Bayes: 
Achieved an accuracy of 96% on the test set.

### Random Forest Classifier: 
Achieved an accuracy of 96% on the test set.
